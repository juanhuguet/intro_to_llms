{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kUZtDdEHhm9C",
   "metadata": {
    "id": "kUZtDdEHhm9C"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade vllm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KtLt51iKhpXT",
   "metadata": {
    "id": "KtLt51iKhpXT"
   },
   "outputs": [],
   "source": [
    "%pip install langchain langchain_community pypdf sentence-transformers chromadb -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c83617ea9b81d",
   "metadata": {},
   "source": [
    "# RAG: Retrieval Augmented Generation\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/juanhuguet/intro_to_llms/blob/main/intro_to_llms/03_local_rag_qa.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "![](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd07c8c5e1a90",
   "metadata": {},
   "source": [
    "![](https://python.langchain.com/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66ada1-c238-4d23-b86a-2b31efb099d1",
   "metadata": {
    "id": "4c66ada1-c238-4d23-b86a-2b31efb099d1"
   },
   "source": [
    "# Importamos las funcionalidades de langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420e5348-6663-4308-ba9f-6dd646f824cc",
   "metadata": {
    "id": "420e5348-6663-4308-ba9f-6dd646f824cc"
   },
   "outputs": [],
   "source": [
    "from langchain_core.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms.vllm import VLLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5594f8a-19e4-4cc9-88aa-2518a97d211e",
   "metadata": {
    "id": "a5594f8a-19e4-4cc9-88aa-2518a97d211e"
   },
   "source": [
    "Seteamos las variables de entorno con la api key de openAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef7c94-d67f-4ff8-b133-52c462264c52",
   "metadata": {
    "id": "b1ef7c94-d67f-4ff8-b133-52c462264c52"
   },
   "source": [
    "## Preprocesamos el pdf\n",
    "\n",
    "PyPDF loader se encarga automáticamente de leer y extraer el texto.\n",
    "\n",
    "El splitter, crea `chunks` a partir del texto de aprox. 1000 caracteres y un overlap de 200 para no perder info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5550a4cc-e772-444c-bc50-ebbc0653bec4",
   "metadata": {
    "id": "5550a4cc-e772-444c-bc50-ebbc0653bec4"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"data/insurance_policy_example.pdf\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "chunks = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb8551-0952-42ba-ad6f-a697be3ec6b9",
   "metadata": {
    "id": "03eb8551-0952-42ba-ad6f-a697be3ec6b9"
   },
   "source": [
    "### Cargamos el documento en la base de datos vectorial.\n",
    "\n",
    "Usamos chroma, que esta en memoría y no requiere setup, y los embeddings a partir de OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82eb64a9-6b1d-4209-92e6-2b9494660b12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82eb64a9-6b1d-4209-92e6-2b9494660b12",
    "outputId": "69f170f2-fdc0-4ce1-be2f-0fac33f43aa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f940f555-dbfe-4de0-8fc8-386bcbbf4734",
   "metadata": {
    "id": "f940f555-dbfe-4de0-8fc8-386bcbbf4734"
   },
   "outputs": [],
   "source": [
    "# populamos la base de datos con los chunks, y los embedings\n",
    "docsearch = Chroma.from_documents(chunks, embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb606b-45f3-4b2a-873a-7cfd35580296",
   "metadata": {
    "id": "a2bb606b-45f3-4b2a-873a-7cfd35580296"
   },
   "source": [
    "### Creamos el `retriever`.\n",
    "\n",
    "Esta pieza permite dada una query, calcular su embedding y recuperar los  k chunks más relevantes para formar el contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a16aab6-b404-405e-9c4e-802acb229241",
   "metadata": {
    "id": "7a16aab6-b404-405e-9c4e-802acb229241"
   },
   "outputs": [],
   "source": [
    "retriever=docsearch.as_retriever(search_type=\"mmr\", fetch_k=10, k=2, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0350d0-545a-45f5-aa47-5c23682ab984",
   "metadata": {
    "id": "1b0350d0-545a-45f5-aa47-5c23682ab984"
   },
   "source": [
    "### Creamos el reader\n",
    "\n",
    "Una vez recuperamos el contexto, lo pasaremos a un llm. Usaremos gpt-3.5-turbo, que tiene un buen ratio performance/coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fdbda8-b03e-4c5d-93e2-2323817836b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17fdbda8-b03e-4c5d-93e2-2323817836b4",
    "outputId": "ea87d57b-f813-4a1d-b822-19973ced9c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-06 15:44:34 config.py:205] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-06 15:44:34 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='TheBloke/Mistral-7B-Instruct-v0.2-AWQ', speculative_config=None, tokenizer='TheBloke/Mistral-7B-Instruct-v0.2-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=10000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=TheBloke/Mistral-7B-Instruct-v0.2-AWQ)\n",
      "INFO 05-06 15:44:34 utils.py:660] Found nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-06 15:44:35 selector.py:69] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 05-06 15:44:35 selector.py:32] Using XFormers backend.\n",
      "INFO 05-06 15:44:35 weight_utils.py:199] Using model weights format ['*.safetensors']\n",
      "INFO 05-06 15:44:45 model_runner.py:175] Loading model weights took 3.8810 GB\n",
      "INFO 05-06 15:44:51 gpu_executor.py:114] # GPU blocks: 3526, # CPU blocks: 2048\n",
      "INFO 05-06 15:44:56 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-06 15:44:56 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-06 15:45:14 model_runner.py:1017] Graph capturing finished in 18 secs.\n"
     ]
    }
   ],
   "source": [
    "reader = VLLM(\n",
    "    model=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n",
    "    trust_remote_code=True,  # mandatory for hf models\n",
    "    max_new_tokens=1000,\n",
    "    top_p=0.95,\n",
    "    stop=[\"\\n\\n\"],\n",
    "    temperature=0.3,\n",
    "    vllm_kwargs={\"quantization\": \"awq\",\n",
    "                 \"max_model_len\": 10000},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eaab4d-5d4e-470e-a1cf-2e84419266e2",
   "metadata": {
    "id": "29eaab4d-5d4e-470e-a1cf-2e84419266e2"
   },
   "source": [
    "## Creamos el prompt\n",
    "\n",
    "Para poder controlar el comportamiento del modelo, creamos un prompt para dar instrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acd98e4-c1ae-48d6-a610-0f7e58f76979",
   "metadata": {
    "id": "0acd98e4-c1ae-48d6-a610-0f7e58f76979"
   },
   "outputs": [],
   "source": [
    "prompt_template = \\\n",
    "\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, don't try to make up an answer and answer `not-in-text`\n",
    "Answer in english only.\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04850e27-6328-4071-bf45-38fa916cfd0d",
   "metadata": {
    "id": "04850e27-6328-4071-bf45-38fa916cfd0d"
   },
   "source": [
    "## Creamos la cadena de QA\n",
    "\n",
    "Usamos el wrapper de langchain que se ocupa de orquestar el flujo de dato:\n",
    "\n",
    "`query` -> `embedding` -> `retrieve context` -> `prompt completion` -> answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8800838b-d140-422f-a797-886062d95c5f",
   "metadata": {
    "id": "8800838b-d140-422f-a797-886062d95c5f"
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=reader,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=retriever,\n",
    "                                 chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                                 return_source_documents=True\n",
    "\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0db433-1227-4855-a581-ee66a7a033f3",
   "metadata": {
    "id": "ce0db433-1227-4855-a581-ee66a7a033f3"
   },
   "source": [
    "## Prueba del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30a920c5-caad-4e22-ad99-75f099950ff2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30a920c5-caad-4e22-ad99-75f099950ff2",
    "outputId": "b162085c-abc0-48ca-e2dd-2ba084c7fbc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.86s/it]\n"
     ]
    }
   ],
   "source": [
    "results = qa(\"What are the issues that are not covered by the insurance ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4614af2d-b147-49c9-97af-baad003e5434",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4614af2d-b147-49c9-97af-baad003e5434",
    "outputId": "d4e6c6d2-5f72-4041-805e-ba9c3b326012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The insurance does not cover:\n",
      "\n",
      "1. Bodily injury or medical expenses that are not reasonable or necessary or already covered under Section II.\n",
      "2. Fines, penalties, restitution orders, or attorney’s fees or costs.\n",
      "3. Punitive damages.\n",
      "4. Damages for any insured other than as specified in the coverage (i.e., damages for care, loss of consortium, loss of services, and negligent entrustment, and includes imputed negligence, agency, conspiracy, the family purpose doctrine, joint enterprise or venture, employment relationship, partnership, concert of action, or negligent hiring or supervision or retention, sustained by the injured person and any other person).\n",
      "5. Multiple policy periods for the same accident or injury, the limits of liability cannot be added, combined, or stacked to increase the coverage.\n",
      "\n",
      "Therefore, the insurance does not cover various issues such as fines, penalties, restitution orders, attorney’s fees or costs, punitive damages, and damages for any insured other than as specified in the coverage for multiple policy periods for the same accident or injury.\n"
     ]
    }
   ],
   "source": [
    "print(results[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bda86ed-9bd1-43ba-a3c2-08a9e99eb087",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bda86ed-9bd1-43ba-a3c2-08a9e99eb087",
    "outputId": "ed69b415-08ad-42bc-f3c2-ad581dcbf072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"SAMPLE DOCUMENT\\n51 to which this coverage applies. We will pay only for \\nservices actually incurred and reported to us within 3 \\nyears from the accident dat e. This coverage does not \\napply to you or regular residents of your  household \\nexcept residence employees . \\n \\nThis coverage applies to:  \\n1. persons on an insured location  with the \\npermission of any insured , and \\n 2. persons off an insured location  if the bodily \\ninjury : \\n a. arises out of a condition on an insured \\nlocation  or the ways immediately \\nadjoining; \\n b. is caused by the activities of any insured ; \\n c. is caused by a residence employee  in the \\ncourse of that residence employee's  \\nemployment by any insured ; or \\n d. is caused by an animal owned by or in the \\ncare or custody of any insured  except any \\nanimal that is excluded under 1.n. of \\nWHAT LOSSES ARE NOT COVERED –  EXCLUSIONS - SECTION II. \\n \\nWHAT LOSSES ARE NOT COVERED – \\nEXCLUSIONS – SECTION II \\n \\n1. Under SECTION II we do not cover:\" metadata={'page': 54, 'source': 'insurance_policy_example.pdf'}\n",
      "page_content='SAMPLE DOCUMENT\\n65  b. that the medical expenses were \\nreasonable or necessary or otherwise \\ncovered under SECTION II. \\n \\n6. Severability of Insurance \\n This insurance applies separately to each \\ninsured , however, this condition will not \\nincrease our limit of liability for any one \\noccurrence . \\n \\n This severability of insurance provision in no \\nway alters or affects any provision of the policy indicating that it applies to “any insured ”. Any \\nlimiting or exclusionary provision in the policy indicating that it applies to “any insured ” \\nmeans that such limiting or exclusionary \\nprovision is applicable as to any insured  under \\nthis policy. Where we use the phrase “any  \\ninsured ”, we intend that such provisions not be \\nlimited to any one insured and that such \\nprovisions are applicable to any insured under \\nthe policy. \\n \\n7. Suits Against Us \\n We may not be sued until all terms of this' metadata={'page': 68, 'source': 'insurance_policy_example.pdf'}\n",
      "page_content='one person includes but is not limited to \\ndamages for care, loss of consortium, loss of \\nservices and negligent entrustment, and includes imputed negligence, agency, \\nconspiracy, the family purpose doctrine, joint \\nenterprise or venture, em ployment relationship, \\npartnership, concert of action, or negligent \\nhiring or supervision or retention sustained as \\nthe result of the same injuries by: \\n a. the injured person; and \\n b. any other person.  \\nIf any insured  has been insured for more than \\none policy period under this or any other homeowners policy issued by us, and an \\naccident, including continuous or repeated injurious exposure to essentially the same conditions, results in bodily injury  or property \\ndamage  during more than one of these policy \\nperiods, the limits of liability of two or more of these policy periods may not be added \\ntogether, combined, or stacked to increase the' metadata={'page': 65, 'source': 'insurance_policy_example.pdf'}\n",
      "page_content='SAMPLE DOCUMENT\\n50 SECTION II – LIABILITY COVERAGES \\n \\nCOVERAGE E – PERSONAL LIABILITY \\nCOVERAGE F – MEDICAL PAYMENTS TO OTHERS \\n \\nWHAT LOSSES ARE COVERED – COVERAGE E \\n 1. We will pay for actual damages that any \\ninsured  is legally obligated to pay due to \\nbodily injury  or property damage  caused by \\nan occurrence  to which this coverage applies. \\n \\n Damages do not include: \\n a. fines; \\n b. penalties; \\n c. restitution orders; or \\n d. attorney’s fees or costs; or \\n e. punitive damages . \\n \\n2. We will defend any suit claiming damages for \\nbodily injury  or property damage  to which \\nthis coverage applies. We will defend suit even \\nif the allegations are groundless, false or \\nfraudulent. Defense lawyers will be provided by \\nus. We may pay the lawyer a flat fee to \\nrepresent you. If any insured  retains a lawyer \\nfor any claim, whether or not covered under this coverage, we will not pay the fees and \\ncosts charged by that lawyer. Our duty to \\ndefend ends when the amount we pay for' metadata={'page': 53, 'source': 'insurance_policy_example.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in results[\"source_documents\"]:\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_n02Zcm2lR-x",
   "metadata": {
    "id": "_n02Zcm2lR-x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
